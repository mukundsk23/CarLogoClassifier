{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Mukund Kathait\\\\Downloads'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A CNN scans the image based on its kernel size i.e. the size of the frame which we specify and in the first pass tries to find some features like edges, corners etc.\n",
    "Next it slides the kernel over the next set of pixels and does this for the entire image.\n",
    "Later, after completing the CONVOLUTION, we perform a pooling on matrix of features. The most common one is MAXpooling, wherein we selet the max value.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('C:\\\\Users\\\\Mukund Kathait\\\\Downloads\\\\10-class-for-car-logo\\\\TrainingData')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrainingData/Buick\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:04<00:00, 230.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrainingData/Citroen\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:07<00:00, 125.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrainingData/VW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:03<00:00, 259.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrainingData/Chery\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:11<00:00, 88.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrainingData/Lexus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:04<00:00, 221.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrainingData/Toyota\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:04<00:00, 247.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrainingData/Mazda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:04<00:00, 203.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrainingData/Honda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:05<00:00, 173.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Honda:  1000\n",
      "VW:  1000\n",
      "Buick:  1000\n",
      "Citroen:  1000\n",
      "Lexus:  1000\n",
      "Toyota:  1000\n",
      "Mazda:  1000\n",
      "Chery:  1000\n"
     ]
    }
   ],
   "source": [
    "#making false since we have a numpy object\n",
    "REBUILD_DATA = True \n",
    "# set to true to one once, then back to false unless you want to change something in your training data.\n",
    "\n",
    "class Cars():\n",
    "    IMG_SIZE = 50\n",
    "    Honda = \"TrainingData/Honda\"\n",
    "    VW = \"TrainingData/VW\"\n",
    "    Buick = \"TrainingData/Buick\"\n",
    "    Citroen  = \"TrainingData/Citroen\"\n",
    "    Lexus = \"TrainingData/Lexus\"\n",
    "    Toyota = \"TrainingData/Toyota\"\n",
    "    Mazda = \"TrainingData/Mazda\"\n",
    "    Chery = \"TrainingData/Chery\"\n",
    "    \n",
    "#     TESTING = \"PetImages/Testing\"\n",
    "    LABELS = { Buick: 0, Citroen: 1, VW: 2, Chery: 3,\n",
    "             Lexus: 4, Toyota: 5, Mazda: 6, Honda: 7  }\n",
    "    training_data = []\n",
    "\n",
    "    honda_count = 0\n",
    "    vw_count = 0\n",
    "    buick_count = 0\n",
    "    citroen_count = 0\n",
    "    lexus_count = 0\n",
    "    toyota_count = 0\n",
    "    mazda_count = 0\n",
    "    chery_count = 0\n",
    "\n",
    "    def make_training_data(self):\n",
    "        #iterate over the dict\n",
    "        for label in self.LABELS:\n",
    "            print(label)\n",
    "            for f in tqdm(os.listdir(label)):\n",
    "                if \"jpg\" in f:\n",
    "                    try:\n",
    "                        path = os.path.join(label, f)\n",
    "                        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "                        img = cv2.resize(img, (self.IMG_SIZE, self.IMG_SIZE))\n",
    "                        #np.eye(8)[self.LABELS[label]] --> contains the label\n",
    "                        #8 since we have 8 classes\n",
    "                        [0,1,0,0,0,0,0,]\n",
    "                        self.training_data.append([np.array(img), np.eye(8)[self.LABELS[label]]])  # do something like print(np.eye(2)[1]), just makes one_hot \n",
    "                        #print(np.eye(2)[self.LABELS[label]])\n",
    "#all the classes should have equal distribution\n",
    "                        if label == self.Honda:\n",
    "                            self.honda_count += 1\n",
    "                        elif label == self.VW:\n",
    "                            self.vw_count += 1\n",
    "                        elif label == self.Buick:\n",
    "                            self.buick_count += 1\n",
    "                        elif label == self.Citroen:\n",
    "                            self.citroen_count += 1\n",
    "                        elif label == self.Lexus:\n",
    "                            self.lexus_count += 1\n",
    "                        elif label == self.Toyota:\n",
    "                            self.toyota_count += 1\n",
    "                        elif label == self.Mazda:\n",
    "                            self.mazda_count += 1\n",
    "                        elif label == self.Chery:\n",
    "                            self.chery_count += 1\n",
    "\n",
    "                    except Exception as e:\n",
    "                        pass\n",
    "                        #print(label, f, str(e))\n",
    "\n",
    "        np.random.shuffle(self.training_data)\n",
    "        np.save(\"training_data.npy\", self.training_data)\n",
    "        print('Honda: ',self.honda_count)\n",
    "        print('VW: ',self.vw_count)\n",
    "        print('Buick: ',self.buick_count)\n",
    "        print('Citroen: ',self.citroen_count)\n",
    "        print('Lexus: ',self.lexus_count)\n",
    "        print('Toyota: ',self.toyota_count)\n",
    "        print('Mazda: ',self.mazda_count)\n",
    "        print('Chery: ',self.chery_count)\n",
    "        \n",
    "\n",
    "if REBUILD_DATA:\n",
    "    car = Cars()\n",
    "    car.make_training_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = np.load(\"training_data.npy\",allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([array([[249, 249, 248, ..., 248, 249, 250],\n",
       "       [253, 253, 253, ..., 255, 254, 254],\n",
       "       [227, 225, 223, ..., 229, 229, 230],\n",
       "       ...,\n",
       "       [245, 246, 247, ..., 249, 252, 249],\n",
       "       [246, 247, 247, ..., 246, 250, 248],\n",
       "       [249, 249, 248, ..., 242, 246, 247]], dtype=uint8),\n",
       "       array([0., 1., 0., 0., 0., 0., 0., 0.])], dtype=object)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 1., 0., 0.])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data[2][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1d814ff86d8>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD6CAYAAABnLjEDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO2daYwe1ZWG34OxMeANgzGmTbCdhUAI4NAYKwaECIsHImxFjEI0GjESkX9kRiLLKPGAhEI0PxhFyiTSzCRCAcUjRSFhiUBkQZYHQiAEaBsMxg7YZrENXsBADDZg2tz50V93vvvW6b63q7uru7nvI1ndp7rurVtV33F959RZLIQAIcRHn8NGewFCiGaQsgtRCFJ2IQpByi5EIUjZhSgEKbsQhTAkZTezpWb2nJltMbOVw7UoIcTwY3Xfs5vZBADPA7gEwA4ATwD4SghhY39jJk6cGCZPnlzreGMBM4vknGvHY4RPzrUcyzEhddY2XOfTPs8HH3yA7u5u90N3+BCOsQjAlhDCCwBgZrcDWAagX2WfPHkyOjs7h3DI0WWklH3ChAmRfOjQocEtbIxz2GHVL5AffvhhJHvnzPuMlrLn3I/u7u7kPnw+LOfgjWnftmXLln7HDuVrfAeA7W3yjtY2IcQYZChPdu+RVfmv18xWAFgBAEccccQQDieEGApDUfYdAE5qk+cCeJV3CiHcAuAWAJg6dWrI+brTjvcVsA51vjLx10b+Su6tLbVe/srujcn52jie/AU51967Lt62drxrkDpWnc9Bjhly+OGxKnmfc74fqfMDhtekG4omPQHgk2Y238wmAbgawL3DsywhxHBT+8keQug2s38BcD+ACQBuCyE8O2wrE0IMK0P5Go8Qwm8B/HaY1iKEGEEUQSdEIQzpyT5YQghJxxI7MdgRkuOwGy5nT4rUO8/c4/A55zhlchxNqWs1XM7PFMOxVg/vnrKjjK93HQedR2peXoc3xrvP7733XiTnOLTbr91ATlk92YUoBCm7EIUgZReiEBq12YG0PZqy3XJsroMHDw5qTTnHrUvKB+Edm+XBBiL1d6ycwI/RIue+ss3r3efhsslTc9bxzdTxC/E9G8r56ckuRCFI2YUoBCm7EIXQqM1+2GGHYcqUKQPuU+e9KI/xbFHeJ8d+Sr3j995pDkfiAq+/rv3H62N5NG32nGuZSuQZT8lAQF49hJT/ZrDHiOYa1ExCiHGLlF2IQpCyC1EIUnYhCqFRB92cOXOwcuXfKk7nOJ6Go0ifNy870rx5eZ/3338/kr2gDt4nZ0zqOHWuE5DnBBsJchxnvLac5CUec+SRRybHpOYA0o7MnKSWHHKSuiZOnBjJkyZNimSvtFv7OV533XX9Hl9PdiEKQcouRCFI2YUohEZt9qlTp+LCCy9s8pDDSo6dzIEqOc0QeFudZhR1bMg6gSw5x65js9expT1S++RU9+V75o2pE/xVJ9kqx7fRfs433nhj/3MN+uhCiHGJlF2IQpCyC1EIUnYhCqFRB92HH35Yq4rMYBmpqjM5XUXZQcRBETlOMa4wWpdURd2R6hbL5+yto861zHHqpZyFOVVneEzOcXI+czmO11QmYuo6DeQc1ZNdiEKQsgtRCFJ2IQqhUZvdzLLa1A6WnE4bw0FOUkVqLd7aeJ7JkydHsmdnDkeVlpxWxKm21UD1uuRUga3jV0kFLHnUSQYarQ49OfOm7rtsdiGElF2IUpCyC1EIjXdxHSl7up2R8AsAwAcffBDJng3mFTpIjeGCBXWSWnJIvbf2tuUkuaTeH9dJjMmhTvJMnWub49uo8549x38wnB1u9GQXohCk7EIUgpRdiEJIKruZ3WZme8xsQ9u2mWa22sw2t34eM7LLFEIMlRwH3c8A/BeA/23bthLAmhDCzWa2siV/Z/iXN7Zgx1/KGQfkBdWwE+btt9+O5BxHVE4FFt4nx0GUE7CUCvzICQry1sKOy1TlVY86bb5y2onVOU6OgzRnn4HGDKn9UwjhIQBv0OZlAFa1fl8FYHlyRUKIUaWuzT47hLATAFo/j+9vRzNbYWZdZtb1+uuv1zycEGKojLiDLoRwSwihM4TQedxxx4304YQQ/VA3qGa3mc0JIew0szkA9uQMMrPIzq0TSOHZRpxokdPBgwNkvHnZRmTbbteuXZUx77zzTiRzUovX0YPtrKOPPjqSPZuR15Zjf+cEG7FNznYxXzePnEQYPidvn/379w84r3efU4Er06ZNq4zh651TTITvY50OPTnk+ALa78lIJMLcC+Ca1u/XALin5jxCiIbIefX2CwCPAjjFzHaY2bUAbgZwiZltBnBJSxZCjGGSX+NDCF/p509fGOa1CCFGkEYTYXbt2oXvf//7fbL3npRt3Hnz5kXymWeeWRlz4oknDnotXgdQZtu2bZHMNrpnZ86cOTOS2Ub0bHa+DjyvZ2ey/ee9/051I2X/AgAcddRRlW3teDY727xsr3rXmtfCnWsB4MCBAwOu5d13361sY/v6zTffjORXXnmlMobv2YwZMwb8OwC88Ub8Nnr79u2R/Nprr1XG7N27N5I5nsLbtm/fvkj+61//OuC8L7/8cuXvvShcVohCkLILUQhSdiEKQcouRCHYSFVF8Zg8eXI46aST2mVvn0hmR84JJ5xQGTN//vxIPu200yr7fPrTn47kqVOnRrIXOMFOsNmzZ0fy9OnTK2PY2cbBL55Tjx1R7Mjx1saOGC+ohs+Zr53nLEwFH3mBITt27IjkBx98MJI9RxqvraOjo7LP8cfHUdjsPPQcvBw4xA4uz3G2e/fuSH711VcjmZ1xAMCh3zt37ozkF198sTKGHb6eA5IdrXztPH1td4ju27cP3d3dboSVnuxCFIKUXYhCkLILUQiNBtUcOnQoCgpgewqo2pFsl3nJD2zbeXYZ23Inn3xyJH/sYx+rjGEbNxVwAlTtv61btw4oA8Bzzz0XyU8++WQkezY72/6XXnppZZ/TTz89kjn4xQuQSRWMyEnwYBv+17/+dWUM0+7L6YXt+k984hOR7N2zz3zmMwPO6wUo8X1m3wz7IIB0QQsvkIj9UZ7NzsFFfJ89n0n7WtQRRgghZReiFKTsQhRC411c221yz+5hm+OYY+LCtQsWLKiMYZuLbVOg+l6dbTm24b218Hq9d9vPPvtsJK9atSqSu7q6KmO8hIh2PDuNbdOzzz67ss/cuXMjmW1E7/3xli1bBpzDu/68beHChZH8m9/8pjJmw4YNkcx2PgA88cQTkcz2treWr371q5HM9rcXW8B+Cf4sXH755ZUxjz/+eCR795Xhd+iezZ5K/vF8Vu3r9/w7vejJLkQhSNmFKAQpuxCFIGUXohAaddBNmjQpcvjkJALkONKOPfbYSPYcN2eddVYks+PGcxbW6ajCDkVO0vESYTjxhZMqvDF8HC9BiNf71ltvRfIdd9xRGfPAAw9EMgfrfOlLX6qM4WOzU2/OnDmVMZwoMmXKlMo+/Fngc+Z7CKQrxXpBQan76l3bxYsXRzI7WdlR663XWws7SHler0Jwu9POq2TTi57sQhSClF2IQpCyC1EIjdrsc+bMwQ033NAnc9AEAKxbty6SuXKsl2DA1T89u57tSE448AppsI3L9qBnS3P1Ww528Sq6ciLMww8/HMls0wPAqaeeGsme/co+B66A6iXlcBeWTZs2RfLatWsrY9iu58Sk5curfT/ZF+PdV7b1Fy1aFMlsNwPVoBlO9vHsZN6Hk688fw5f73POOSeSOSEKqN57DvQCqv4nTvY577zzKmPaP7s/+tGPKn/vRU92IQpByi5EIUjZhSiERgtOdnZ2hvYEAq87ByeO8HtDtlWB6jt0770o25H8DtcreMHvSrl4gldwgd/Rsm/AS8RIzZGDdx95nj174ma7nl3Jfghus+213U51hPF8G+xP8IpHphKRcs6Z77P3mdu4cWMk8/ovu+yyyhh+383vw9nvAgB//OMfI9nz3/Dn/YwzzojkFStWVMa0xx8sXrwYa9euVcFJIUpGyi5EIUjZhSgEKbsQhdBoUE0IIXJ+eM4qbpfLjhx2tAFVR5nXYpcdNxxI4QWL/P73v4/kCy64YMC1etvY2ZOTcMN4DjueJ6e7y6xZsyLZq7TKjjKewwtK4eooHKCUU5XXI3XPcpyqLHuBXJs3b45kbhPuXdtLLrkkkjkoyKuWxHifBT4WOwK9SjXt11/VZYUQUnYhSiGp7GZ2kpk9YGabzOxZM7uutX2mma02s82tn8ek5hJCjB45Nns3gG+FENaZ2VQAa81sNYB/ArAmhHCzma0EsBLAdwaaKIQQdaX0kk848P/Pf/5zJD/zzDOVMZww4SVVsC3KnTr/8Ic/VMZwsAUH1XCRCaBqc/FaPJvrzTffjGROfPHsP66I6s2bCvDhpBeg2qWHbXTP/uZrmzouUD1Hz/7mrqd87/n+ANVuOhyk4tnf7AvgIhmcEOWNySmSkeoiA1SvPwcFeeQGYSWf7CGEnSGEda3f3wawCUAHgGUAesPdVgGopjYJIcYMg7LZzWwegIUAHgMwO4SwE+j5DwFA1U0uhBgzZCu7mU0BcBeAr4cQqh0Z+x+3wsy6zKyLG9gLIZojS9nNbCJ6FP3nIYS7W5t3m9mc1t/nANjjjQ0h3BJC6AwhdHpJFEKIZkg66KzH+r8VwKYQwg/a/nQvgGsA3Nz6eU/GXJHDKsfxwbBjDQCeeuqpSPZa+bKjjB1EXtWWXbt2RfJ9990XyX/5y18qY84999xI5rbDXnVQPvZDDz0Uyd414fZPXtVXrs7zyCOPRPJdd91VGcPnzE7U888/vzLmqquuimR2Hnotj2+77bZIfumllyr78DdBzhLznFepFl2eI5CrIXEFHK/9U8op6Tnj+DPHjlmgmj3Hzk2vvZOXMeiR441fAuAfATxjZr1adT16lPxXZnYtgG0A/j7riEKIUSGp7CGEhwH059v/wvAuRwgxUiiCTohCaLxlc3vShxdUw22EOUnBs1m4SqfXipiTQDhhxUtq4QorHOTh+Q84qIMTd3KCathW9cZw4IdX9YT9A2yPP/roo5UxXM2Gnarc4Qao2ui8Fg6MAqpJRjnJPmyje58f7jLE83rdaZYuXRrJX/7yl5PH4eQl9qu0B4/1N4bvB1BdP3fo8eZtx/tM9h1/wJFCiI8MUnYhCkHKLkQhNGqz79u3D6tXr+6TvU6XXIGT7RqviwZ3BPUKFLDNzrYoF6YAgOeffz6SX3755Uj23vNy7AAny3iFKngeLkDg2ew7duyIZC/ZhOfhbiNekBPbfLxengOo3hNOWOE4CG9t3voZ9g1415/3Yb+FF+fARTzYz+KNYRudP4P82QGqHXk8Pwvb5JwYw8cB4nvk+av69uv3L0KIjxRSdiEKQcouRCFI2YUohEYddLt3745aynqtiNkhkQM7sLyqM+xQWbJkSSRzAgtQbaXMwS5eIg8HcbDDxQuK4EQGPh8vqYLX4jluOFnmlFNOiWS+BkD1+n/uc5+L5M9//vOVMewUYyefFzzC98NzgnG1F762XoAVV6LhgJgpU6ZUxkyfPj2S2SnpBfw8/fTTkcyfOW49DlQ/7976+fPBgV2pllcDVbbRk12IQpCyC1EIUnYhCqFRm727uzuyWzyb16vK2Y4XNMA2rdcimG1RDnBYtmxZZcy1114byWxLtwcI9cLBLmxjebYpw/asd014/V7gSmdnZyRzMYurr766Muaiiy4acIwXiMNVXrlYBScQAdV75CWbpCqrepViufotVwS+8sorK2OuuOKKSObrf+edd1bGPPbYY5HM18D7nHKlW88/xZ8x9h/ktKnuDz3ZhSgEKbsQhSBlF6IQbKCuj8PNrFmzwvLlf+sl4ZWW5oJ7qfeOgJ8owvD7VU7e4E6wAHDxxRdHMhey9Ozk+++/P5L5/fcrr7xSGcPnzO+tvYKTXECTC1sC1U6jJ598cnIM27hsZ3pdWDjxiAtTeAlPnPjidZphm5338Tr6fvazn41kLh556qmnVsbw9eeOvt45c8ER9j/xdQOq79U9W5u3pWIwgNgPtHXrVrz77ruuEa8nuxCFIGUXohCk7EIUgpRdiEJo1EF3+umnh7vvvrtP9pwY3LGDnSfeGHb0bdmypbIPVw5hx4fXFpkrkXI1G8/Zww4Urtrypz/9qTKGA3HYqedVNOFgCy/YhZN75s2bF8lea2uehx1PXlLLCy+8EMl8zl7nEw4U8qr78lr4enuJPOx05OOsWbOmMoY78HBAjNdxhT+nHBTEzlCg6hRmRywAzJ49O5JTVZGBOLjo+uuvx9atW+WgE6JkpOxCFIKUXYhCaNRmP/vss0N7dxCv0mqqYIGXFMI2rZdgw4kLv/vd7yLZ66TBgR9sc3H3T6Aa1LFgwYJI9uw/DhTi8/GKfPA5ekkjbKNzUotHqqOKl8jDXWQ4Sce7zxwQ4wXIsB3M8/BagWpnXQ7o8e4zX28+Ry9Jh4N12J/j2ezsF/I+C3yOfGxvLe336Nxzz0VXV5dsdiFKRsouRCFI2YUohEaLV4QQokITOYn4/N7aSx7gJBfvXSTbq5/61KciuaurqzLmkUceiWR+/71+/frKGH7nPHPmzEj23ufzu1Vem+cbOOOMMyLZ65TD3Vu482tOkUcmpwsO+xg4VsIbw7EG3ratW7dGspcglEpI8ez8jo6OSF60aFEkc1dXoJo4xV1l6nT+8eB9vHNuP9ZAc+rJLkQhSNmFKAQpuxCFkFR2M5tsZo+b2Xoze9bMbmptn29mj5nZZjP7pZlVXxoKIcYMyaAa6/GIHR1CeMfMJgJ4GMB1AL4J4O4Qwu1m9hMA60MIPx5oLg6q8ZxBvI0dHZ6Dgh0fnhOP5+EkEM+hwg4hrsjCCR9ANQmHHUZeRxh2QnKQjVfFhbuYeEktXqJFO56zkD8PfC09B12qupDX+YQdZ17XG77XHFDi3Wc+549//OORfM4551TGLFy4MJK5k44XyMKfUz7nnLV5n3/+HPJnwxvTHvx1wQUXYN26dfWCakIPvSFGE1v/AoCLAPTW2F0FYLkzXAgxRsiy2c1sgpk9BWAPgNUAtgJ4K4TQ+9/xDgAd/YxdYWZdZtbl1ZwTQjRDlrKHEA6FEM4CMBfAIgDVRO6ep7039pYQQmcIodPLuRZCNMOggmpCCG+Z2YMAFgOYYWaHt57ucwFUMwyI999/H5s3b+6TvUQADvRgO8ezM3lbjs3OtqdXtZaryXJyw9KlSytjuHrsSy+9FMnsBwCqhRByOofwNu9bE9t3Od1pUl1YPFKBON5xOJAoJxGGA5TYHgeqwS6cDMTHzaFOshgnUQF5/hv2U7DMnxXe5iWB9ZLjjZ9lZjNavx8J4GIAmwA8AOCq1m7XALgnNZcQYvTIebLPAbDKzCag5z+HX4UQ7jOzjQBuN7N/B/AkgFtHcJ1CiCGSVPYQwtMAFjrbX0CP/S6EGAcogk6IQmi0Us2MGTPC+eef3yd7gSDchpcDSjwHC3v5vaw3noflnLUwnG0HACeccEIkc/CL56xi5yEHmHjVWdlR47UI3r9/fySzsycnMysV5ORt42vL2XZANSPPu2d8bHaiesE67Bjja+BV6vWcae14lYJ4DFfr8arw8jxepWReHzvxUq2g9+zZg4MHD6pSjRAlI2UXohCk7EIUQqM2+xFHHBHaq654SS2plrWezcjk7MPzevZ5KqDHS1Bh25/38ex8HsPJDzl2sucL4HPMOWeel+3mnEQk3scLWGKb17O/+bOZE2zElWg4ScdLuOFtbCd7OsLnxOfjBRrxdfLOOVXNxltL+7b33nsPhw4dks0uRMlI2YUoBCm7EIXQeHXZdtvGS1hJvUv1bCG2Eb2iDRlFOgb8ey6ppJAceP05hRC8c2bbn2XPzud5+Nrye2sgnTzj2fmpd9tA9bz5s5Hjb6pzX1N+CyBtW3t+Fr7eKfsbyFt/7jnqyS5EIUjZhSgEKbsQhSBlF6IQGnXQTZs2DZdddlmf7DlpOOmDK294gQjsuPECJ1L7eE6YnH0YdpbUcSJ558jw+XgOIZ431VrL28aOKO+epdpse/eDyblOfBzPwcjH5uviObNS18kbk3J+evcjx/nG1XnYYZpyqm7atKny97419fsXIcRHCim7EIUgZReiEBq12U888UTcdNNNfbJn/6WKMnhjOHHBS7xge4/tYq8qJx+b/Qk5xRN4n5zkhxzfQE6CRB1ShTS89fM+PIdnv7JtWifBKSdwhW3pnIrGLHvJS1yUhAuocAtnoHrOns+E9+G1pDr/fOMb36j8vRc92YUoBCm7EIUgZReiEBq12SdOnBgVjPSSN+bPnz/gHN57xhwb1xvXjvcuOFX4ICeRIafDSuq9tHecHDs/1REmp4tMqkOJtxYuiuEVnOSiHjnvzPnz4l2X1Hv2HJudx3jH4bXwvDnn45Hax/t7+/q++93v9jtWT3YhCkHKLkQhSNmFKAQpuxCF0HilmnYHjxcUkXK25TjFPOcIB96wU8kb41WPbSfHMZgTCJJyKnkMtuqoJy9YsCA5hslxMuWsrc45M3WqAtUZk5M8w+dYJ2kKSCfueEFN7To1kENYT3YhCkHKLkQhSNmFKIRGbfaDBw9i27ZtfbIX4MA2Cgf+e0kJnFDgBcjwvBz44dlPbP/wPqlAHaCebZ0TiDNSsK2Z08WVySngwffIu5a8rU7CUJ315vgleP0cbMQ+IqDarSYnQInHvPjii5Ux27dv7/vdC5TqRU92IQpByi5EIWQru5lNMLMnzey+ljzfzB4zs81m9kszq34nF0KMGbK7uJrZNwF0ApgWQviimf0KwN0hhNvN7CcA1ocQfjzQHFOnTg2dnZ19ck7y/syZMyO5o6OjMoYLB/AcQDVxgffxigKwXc9dXL0EjxkzZgx4nBw7n/GuU8qe9chJJGFy3h/XeXed8od4x+YxnKgEVIuQ7N27N5K9jjZsX+d0mOV9uLDJq6++WhnD9vQ777xT2YfPidfmrb+9WMtrr72GgwcP1u/iamZzAVwB4Kct2QBcBODO1i6rACzPmUsIMTrkfo3/IYBvA+j9L/xYAG+FEHpdkjsAVB+5AMxshZl1mVmX530UQjRDUtnN7IsA9oQQ1rZvdnZ1vxOGEG4JIXSGEDq9/HUhRDPkvGdfAuBKM7scwGQA09DzpJ9hZoe3nu5zAVSNFCHEmCHbQQcAZnYhgH9tOejuAHBXm4Pu6RDC/ww0ftKkSWHWrFnt81X2SQWheA6unG4cqYolXoAPz8sOO8+px0E/ORVFeVuqQguQrq7i7ZPTXYTnYadYTrcddth5zkMe41UNTgWueI4z3sZOsJyOQix75mcqcMircJzjRE1dO88Z2r6WAwcO4NChQ/UddP3wHQDfNLMt6LHhbx3CXEKIEWZQ4bIhhAcBPNj6/QUAi4Z/SUKIkUARdEIUwqgWr8ixGVn2bBa29zwbKxUc4tlTPIbt+pxOnakKrx45by1ygnNS1zIn+YTxrm3K5vXs/BxfTKrKq2fn8z51urjmBBKlEmxStnV/c7D/JtWthucdKIlHT3YhCkHKLkQhSNmFKIRGbfZJkyZFHV88O5m35XQkySmEkCrKUKcQQk5SSI6dVsefwHZxji3KeO/8c2xchteXsjuBer4MPo4XG5HyU+ScD+P5UFIFL7zj8HpzfDM5XWjbz3Hjxo39zqUnuxCFIGUXohCk7EIUgpRdiEJo1EHX0dGB733ve32yFxTBlThY3rdvX3IMV+T0jpUKBAGqjr+UDKQTF7xz5uQMrk5SN6liOMYwOR1tUgk43hgvqShV5cdzgnGyUirJyNsnNYe3jWWvWtLUqVMj2auUzNWPeJ5UFaavfe1rlb/3oie7EIUgZReiEKTsQhRCozb7tGnTcOmll/bJOd1R2ObNscc92F5luU6lVc9mT5Fjs3OF0ZwiDZ49zteO1+vZ0qnrktN5NKdzLdueXLkX6Pm8DLTenIIjTE63ID5OTiAOn2NO5WT2DXjHHmx3W75m0VyDmkkIMW6RsgtRCFJ2IQpByi5EITTqoAPyHGHtsIPCC0TgYAXvGByQkdNKmR0zdTK1cuDj5DgP6wTI5LRSHg5yMgjZuZZTqabOcZicisY5Y+rsk/OZY8frYLMzB/pc6MkuRCFI2YUoBCm7EIXQqM1+4MABrF+/vk/OsdM4yCCnuopnt/A8LHsBDpycweutU92mTuUXz7bjY+ckqORU2hkOco7DwS1esg/D83iBOHyP+DheUBZvY7s5p9IOV1DygndyGpvytdu5c2ckb9u2rTKmfZ89e/b0P3fy6EKIjwRSdiEKQcouRCEMqovrUJk+fXpYsmRJn5zTeTSnEALv4yX4pwoUeGP4nf5RRx014JxAXhIIw7Y1v4POuUc51WVTHVZyqJMwlNNtx7PrU/t4NnAq+YcLgwDVTq9sw+cUNuEEJy95idebc114Hs8X0H7OGzZswP79+4e9i6sQYhwhZReiEKTsQhSClF2IQmg0qKa7uxt79+7tk4crqCPHCcb75FSZyWljxKScYjnBL6kKtbkMRyukHEdaan05Y+qco3cPUxVjvOtfpzVYylGZEwjlzcvOwMG2nB7oOurJLkQhSNmFKAQpuxCF0GhQjZm9BuBlAMcBeL2xAw+N8bRWYHytdzytFRgf6z05hDDL+0Ojyt53ULOuEEJn4weuwXhaKzC+1jue1gqMv/Uy+hovRCFI2YUohNFS9ltG6bh1GE9rBcbXesfTWoHxt96IUbHZhRDNo6/xQhRCo8puZkvN7Dkz22JmK5s8dg5mdpuZ7TGzDW3bZprZajPb3Pp5zGiusRczO8nMHjCzTWb2rJld19o+Vtc72cweN7P1rfXe1No+38wea633l2ZW7dY4SpjZBDN70szua8ljdq05NKbsZjYBwH8D+DsApwH4ipmd1tTxM/kZgKW0bSWANSGETwJY05LHAt0AvhVCOBXAYgD/3LqeY3W97wO4KIRwJoCzACw1s8UA/gPAf7bW+yaAa0dxjcx1ADa1yWN5rUmafLIvArAlhPBCCOEggNsBLGvw+ElCCA8BeIM2LwOwqvX7KgDLG11UP4QQdoYQ1rV+fxs9H8oOjN31hhBCb0mYia1/AcBFAO5sbR8z6zWzuZkVX0AAAAHPSURBVACuAPDTlmwYo2vNpUll7wCwvU3e0do21pkdQtgJ9CgYgONHeT0VzGwegIUAHsMYXm/ra/FTAPYAWA1gK4C3Qgi96Wtj6TPxQwDfBtCbRnYsxu5as2hS2b18Sr0KGCJmNgXAXQC+HkLYN9rrGYgQwqEQwlkA5qLnm96p3m7NrqqKmX0RwJ4Qwtr2zc6uo77WwdBkPvsOACe1yXMBvNrg8euy28zmhBB2mtkc9DyVxgRmNhE9iv7zEMLdrc1jdr29hBDeMrMH0eNrmGFmh7eemGPlM7EEwJVmdjmAyQCmoedJPxbXmk2TT/YnAHyy5dGcBOBqAPc2ePy63Avgmtbv1wC4ZxTX0kfLhrwVwKYQwg/a/jRW1zvLzGa0fj8SwMXo8TM8AOCq1m5jYr0hhH8LIcwNIcxDz+f0/0II/4AxuNZBEUJo7B+AywE8jx5b7YYmj525vl8A2AngA/R8E7kWPbbaGgCbWz9njvY6W2s9Dz1fI58G8FTr3+VjeL1nAHiytd4NAG5sbV8A4HEAWwDcAeCI0V4rrftCAPeNh7Wm/imCTohCUASdEIUgZReiEKTsQhSClF2IQpCyC1EIUnYhCkHKLkQhSNmFKIT/B94MZm1XyxP5AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(training_data[2][0],cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv3): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (fc2): Linear(in_features=512, out_features=8, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "# class Net(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "# #         nn.Conv2d(input is 1, 32 is the convulution features\n",
    "# #                  and 5 is the kernel size)\n",
    "#         self.conv1 = nn.Conv2d(1,32,5)\n",
    "#         self.conv2 = nn.Conv2d(32,64,5)\n",
    "#         self.conv3 = nn.Conv2d(64,128,5)\n",
    "        \n",
    "# #Since there is no way to flatten the data,\n",
    "# #we pass fake data and figure out whats the shape\n",
    "# #not clearly given in pytorch documents\n",
    "# #x = torch.randn(50,50).view(-1(how so many features we have),[1,50,50]-->tensor)\n",
    "#         x = torch.randn(50,50).view(-1,1,50,50)\n",
    "#         self._to_linear = None\n",
    "# #Part of forward method but not whole\n",
    "#         self.convs(x)\n",
    "#         self.fc1 = nn.Linear(self._to_linear,512)\n",
    "#         self.fc2 = nn.Linear(512,2)\n",
    "        \n",
    "#     def convs(self,x):\n",
    "#         x = F.max_pool2d(F.relu(self.conv1(x)),(2,2))\n",
    "#         x = F.max_pool2d(F.relu(self.conv2(x)),(2,2))\n",
    "#         x = F.max_pool2d(F.relu(self.conv3(x)),(2,2))\n",
    "        \n",
    "#         print(x[0].shape)       \n",
    "        \n",
    "        \n",
    "#         if self._to_linear is None:\n",
    "#       #X is coming in as a batch of data ex.(3,5,5)      \n",
    "#             self._to_linear = x[0].shape[0]*x[0].shape[1]*x[0].shape[2]\n",
    "#             return x\n",
    "        \n",
    "#     def forward(self,x):\n",
    "#         x = self.convs(x)\n",
    "#         #Here after passing fake data, we come to know\n",
    "#         #the size required for input\n",
    "#         x = x.view(-1,self._to_linear)\n",
    "#         x = F.relu(self.fc1(x))\n",
    "#         x = self.fc2(x)\n",
    "        \n",
    "#         return F.softmax(x,dim=1)\n",
    "        \n",
    "        \n",
    "# net = Net()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__() # just run the init of parent class (nn.Module)\n",
    "        self.conv1 = nn.Conv2d(1, 32, 5) # input is 1 image, 32 output channels, 5x5 kernel / window\n",
    "        self.conv2 = nn.Conv2d(32, 64, 5) # input is 32, bc the first layer output 32. Then we say the output will be 64 channels, 5x5 kernel / window\n",
    "        self.conv3 = nn.Conv2d(64, 128, 5)\n",
    "\n",
    "        x = torch.randn(50,50).view(-1,1,50,50)\n",
    "        self._to_linear = None\n",
    "        self.convs(x)\n",
    "\n",
    "        self.fc1 = nn.Linear(self._to_linear, 512) #flattening.\n",
    "        self.fc2 = nn.Linear(512, 8) # 512 in, 8 out bc we're doing 8 classes\n",
    "\n",
    "    def convs(self, x):\n",
    "        # max pooling over 2x2\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), (2, 2))\n",
    "        x = F.max_pool2d(F.relu(self.conv3(x)), (2, 2))\n",
    "\n",
    "        if self._to_linear is None:\n",
    "            self._to_linear = x[0].shape[0]*x[0].shape[1]*x[0].shape[2]\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.convs(x)\n",
    "        x = x.view(-1, self._to_linear)  # .view is reshape ... this flattens X before \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x) # bc this is our output layer. No activation here.\n",
    "        return F.softmax(x, dim=1)\n",
    "\n",
    "\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "loss_function = nn.MSELoss()\n",
    "\n",
    "X = torch.Tensor([i[0] for i in training_data]).view(-1,50,50)\n",
    "#To scale the images\n",
    "X = X/255.0\n",
    "\n",
    "y = torch.Tensor([i[1] for i in training_data])\n",
    "\n",
    "VAL_PCT = 0.1\n",
    "val_size = int(len(X)*VAL_PCT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7200\n",
      "800\n"
     ]
    }
   ],
   "source": [
    "train_X = X[:-val_size]\n",
    "train_y = y[:-val_size]\n",
    "\n",
    "test_X = X[-val_size:]\n",
    "test_y = y[-val_size:]\n",
    "\n",
    "print(len(train_X))\n",
    "print(len(test_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 144/144 [00:56<00:00,  2.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Loss: 0.00852588564157486\n"
     ]
    }
   ],
   "source": [
    "# BATCH_SIZE = 100\n",
    "\n",
    "# EPOCHS = 1\n",
    "\n",
    "# for epoch in range(EPOCHS):\n",
    "#     for i in tqdm(range(0, len(train_X), BATCH_SIZE)):\n",
    "#         batch_X = train_X[i:i+BATCH_SIZE].view(-1,1,50,50)\n",
    "#         batch_y = train_y[i:i+BATCH_SIZE]\n",
    "# #if you have multiple optimizers, use this        \n",
    "# #         optimizer.zero_grad()\n",
    "        \n",
    "#     #For entire network zero the gradients\n",
    "#         net.zero_grad()\n",
    "#         outputs = net(batch_X)\n",
    "        \n",
    "#         loss = loss_function(outputs, batch_y)\n",
    "#         loss.backward()\n",
    "#         optimizer.steop()\n",
    "        \n",
    "# print(loss)\n",
    "        \n",
    "    \n",
    "BATCH_SIZE = 50\n",
    "EPOCHS = 1\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    for i in tqdm(range(0, len(train_X), BATCH_SIZE)): # from 0, to the len of x, stepping BATCH_SIZE at a time. [:50] ..for now just to dev\n",
    "        #print(f\"{i}:{i+BATCH_SIZE}\")\n",
    "        batch_X = train_X[i:i+BATCH_SIZE].view(-1, 1, 50, 50)\n",
    "        batch_y = train_y[i:i+BATCH_SIZE]\n",
    "\n",
    "        net.zero_grad()\n",
    "\n",
    "        outputs = net(batch_X)\n",
    "        loss = loss_function(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()    # Does the update\n",
    "\n",
    "    print(f\"Epoch: {epoch}. Loss: {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 800/800 [00:07<00:00, 108.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  0.941\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "#We have net.eval, net.train\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in tqdm(range(len(test_X))):\n",
    "        real_class = torch.argmax(test_y[i])\n",
    "        net_out = net(test_X[i].view(-1,1,50,50))[0]\n",
    "        predicted_class = torch.argmax(net_out)\n",
    "        \n",
    "        if predicted_class == real_class:\n",
    "            correct += 1\n",
    "            \n",
    "        total += 1\n",
    "        \n",
    "print(\"Accuracy : \", round(correct/total,3))\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on GPU\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    print(\"Running on GPU\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Running on CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv3): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (fc2): Linear(in_features=512, out_features=8, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                          | 0/144 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected 4-dimensional input for 4-dimensional weight 32 1 5 5, but got 3-dimensional input of size [1, 50, 50] instead",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-64-4b7d28e3c007>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Epoch : {epoch}, Loss : {loss}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-64-4b7d28e3c007>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(net)\u001b[0m\n\u001b[0;32m     10\u001b[0m             \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_X\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_fucntion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-47-e64676ecb72b>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_to_linear\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# .view is reshape ... this flattens X before\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-47-e64676ecb72b>\u001b[0m in \u001b[0;36mconvs\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     72\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mconvs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[1;31m# max pooling over 2x2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_pool2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_pool2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_pool2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 345\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv2d_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    346\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mconv2d_forward\u001b[1;34m(self, input, weight)\u001b[0m\n\u001b[0;32m    340\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m    341\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[1;32m--> 342\u001b[1;33m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[0;32m    343\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected 4-dimensional input for 4-dimensional weight 32 1 5 5, but got 3-dimensional input of size [1, 50, 50] instead"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 50\n",
    "EPOCHS = 3\n",
    "def train(net):\n",
    "    optimzer = optim.Adam(net.parameters(), lr=0.001)\n",
    "    loss_fucntion = nn.MSELoss()\n",
    "    for epoch in range(EPOCHS):\n",
    "        for i in tqdm(range(0,len(train_X),BATCH_SIZE)):\n",
    "            batch_X = train_X[i:i+BATCH_SIZE].view(-1,1,50,50).to(device)[0]\n",
    "            batch_y = train_y[i:i+BATCH_SIZE].to(device)\n",
    "            net.zero_grad()\n",
    "\n",
    "            outputs = net(batch_X)\n",
    "            loss = loss_fucntion(outputs,batch_y)\n",
    "            loss.backward()\n",
    "            optimzer.step()\n",
    "\n",
    "        print(f\"Epoch : {epoch}, Loss : {loss}\")\n",
    "    \n",
    "train(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 800/800 [00:04<00:00, 190.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  1.0\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 800/800 [00:03<00:00, 243.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "test_X.to(device)\n",
    "test_y.to(device)\n",
    "\n",
    "def test(net):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for i in tqdm(range(len(test_X))):\n",
    "            real_class = torch.argmax(test_y[i]).to(device)\n",
    "            net_out = net(test_X[i].view(-1, 1, 50, 50).to(device))[0]  # returns a list, \n",
    "            predicted_class = torch.argmax(net_out)\n",
    "\n",
    "            if predicted_class == real_class:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "\n",
    "    print(\"Accuracy: \", round(correct/total, 3))\n",
    "\n",
    "test(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 14.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "for i in tqdm(range(0, len(test_X), BATCH_SIZE)):\n",
    "\n",
    "    batch_X = test_X[i:i+BATCH_SIZE].view(-1, 1, 50, 50).to(device)\n",
    "    batch_y = test_y[i:i+BATCH_SIZE].to(device)\n",
    "    batch_out = net(batch_X)\n",
    "\n",
    "    out_maxes = [torch.argmax(i) for i in batch_out]\n",
    "    target_maxes = [torch.argmax(i) for i in batch_y]\n",
    "    for i,j in zip(out_maxes, target_maxes):\n",
    "        if i == j:\n",
    "            correct += 1\n",
    "        total += 1\n",
    "print(\"Accuracy: \", round(correct/total, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = net.to(device)\n",
    "\n",
    "def train(net):\n",
    "    BATCH_SIZE = 100\n",
    "    EPOCHS = 3\n",
    "    for epoch in range(EPOCHS):\n",
    "        for i in tqdm(range(0, len(train_X), BATCH_SIZE)):\n",
    "            batch_X = train_X[i:i+BATCH_SIZE].view(-1,1,50,50)\n",
    "            batch_y = train_y[i:i+BATCH_SIZE]\n",
    "\n",
    "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "\n",
    "            net.zero_grad()\n",
    "            outputs = net(batch_X)\n",
    "\n",
    "            matches  = [torch.argmax(i)==torch.argmax(j) for i, j in zip(outputs, batch_y)]\n",
    "            in_sample_acc = matches.count(True)/len(matches)\n",
    "\n",
    "            loss = loss_function(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(loss)\n",
    "        print(\"In-sample acc:\",round(in_sample_acc, 2))\n",
    "\n",
    "train(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
